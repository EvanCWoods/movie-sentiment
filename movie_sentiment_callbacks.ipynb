{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie-sentiment-callbacks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIc/qCAA+Mq8KPStKRUSUy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lYHvokP8tZD"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdk7E8AMXbHO",
        "outputId": "bd0ff263-8f5f-408f-8856-e60acb19bd85"
      },
      "source": [
        "imdb = tf.keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjbuTyRDZRAo"
      },
      "source": [
        "max_length = 256\n",
        "embedding_dim = 16\n",
        "vocab_size = 10000"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyoYPSLWXkz9"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "\n",
        "word_index['<PAD>'] = 0\n",
        "word_index['<START>'] = 1\n",
        "word_index['<UNK>'] = 2\n",
        "word_index['<UNUSED>'] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4iMh6AjYTYv"
      },
      "source": [
        "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                           maxlen=max_length,\n",
        "                                                           padding='post',\n",
        "                                                           value=word_index['<PAD>'])\n",
        "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                         maxlen=max_length,\n",
        "                                                         padding='post',\n",
        "                                                         value=word_index['<PAD>'])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iorRVuFvY2Ae"
      },
      "source": [
        "def decode_review(text):\n",
        "  return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziMUXC0AZ_oU"
      },
      "source": [
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if (logs.get('accuracy') > 0.97):\n",
        "      print('97% accuracy achieved, stopping training.')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callback = MyCallback()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLwcif4pZF3A",
        "outputId": "c647f2df-5823-4f98-87d1-baab5ae38b52"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "                    epochs=10,\n",
        "                    validation_data=(test_data, test_labels),\n",
        "                                     callbacks=[callback])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 189s 237ms/step - loss: 0.5076 - accuracy: 0.7408 - val_loss: 0.3822 - val_accuracy: 0.8439\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 185s 237ms/step - loss: 0.2919 - accuracy: 0.8880 - val_loss: 0.3198 - val_accuracy: 0.8749\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 186s 238ms/step - loss: 0.2051 - accuracy: 0.9255 - val_loss: 0.3588 - val_accuracy: 0.8585\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 186s 238ms/step - loss: 0.1626 - accuracy: 0.9430 - val_loss: 0.3486 - val_accuracy: 0.8560\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 186s 238ms/step - loss: 0.1424 - accuracy: 0.9491 - val_loss: 0.4399 - val_accuracy: 0.8554\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 187s 239ms/step - loss: 0.1028 - accuracy: 0.9652 - val_loss: 0.4521 - val_accuracy: 0.8572\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 184s 236ms/step - loss: 0.0892 - accuracy: 0.9706 - val_loss: 0.4704 - val_accuracy: 0.8009\n",
            "97% accuracy achieved, stopping training.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}